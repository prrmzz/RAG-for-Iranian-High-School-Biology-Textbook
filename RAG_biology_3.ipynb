{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPdooFz0SuEDsMNzKARCuLt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d28c902d9304cf0888ee048acc724f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bb3cc89418149429af251b1f691d3eb",
              "IPY_MODEL_d2d87237f8634f6c90dfd02f366498f1",
              "IPY_MODEL_4ccd18d1f82342948269f1cff23a981a"
            ],
            "layout": "IPY_MODEL_5630c5be62e94d628d1e2de11dc2bc92"
          }
        },
        "1bb3cc89418149429af251b1f691d3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1f36fdde10944019901b7d09475ab33",
            "placeholder": "​",
            "style": "IPY_MODEL_74437b83a435436cbf6e17234d078b6c",
            "value": "Batches: 100%"
          }
        },
        "d2d87237f8634f6c90dfd02f366498f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_357d447c5e834c68a57255aeac247dab",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_009d70d256724cd0ab16ace4377445eb",
            "value": 17
          }
        },
        "4ccd18d1f82342948269f1cff23a981a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0363dbcb89488a813171a13c960402",
            "placeholder": "​",
            "style": "IPY_MODEL_8ae08697e84f4edbb07055604c5b8ce9",
            "value": " 17/17 [00:29&lt;00:00,  1.04it/s]"
          }
        },
        "5630c5be62e94d628d1e2de11dc2bc92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1f36fdde10944019901b7d09475ab33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74437b83a435436cbf6e17234d078b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "357d447c5e834c68a57255aeac247dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009d70d256724cd0ab16ace4377445eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad0363dbcb89488a813171a13c960402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae08697e84f4edbb07055604c5b8ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5f2525b6f248e5a16a3209a3211d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d119891a6cb6422c9aefc97ec12f11e6",
              "IPY_MODEL_cb45eac55de9425bb0252c9147823eaa",
              "IPY_MODEL_1d0a477c5e984bd3ab23a248d8b7fc8f"
            ],
            "layout": "IPY_MODEL_4f1a3b38953344e1ac71d039a487362a"
          }
        },
        "d119891a6cb6422c9aefc97ec12f11e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f09d495d86d4414991d9df8e92745f0",
            "placeholder": "​",
            "style": "IPY_MODEL_e9b8cf559a2d4fd883247523a6e263a8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cb45eac55de9425bb0252c9147823eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e5dad7af216462b9bc2aab90a6d71e5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c40eb4c18d14b85983ce736c9b4acd8",
            "value": 2
          }
        },
        "1d0a477c5e984bd3ab23a248d8b7fc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6b3b529cd8466abba451c1c5ffa464",
            "placeholder": "​",
            "style": "IPY_MODEL_0c77bb37a58041219435cba14d27bc35",
            "value": " 2/2 [00:26&lt;00:00, 12.69s/it]"
          }
        },
        "4f1a3b38953344e1ac71d039a487362a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f09d495d86d4414991d9df8e92745f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b8cf559a2d4fd883247523a6e263a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e5dad7af216462b9bc2aab90a6d71e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c40eb4c18d14b85983ce736c9b4acd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e6b3b529cd8466abba451c1c5ffa464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c77bb37a58041219435cba14d27bc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prrmzz/RAG-for-Iranian-High-School-Biology-Textbook/blob/main/RAG_biology_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PIP (ML + Persian text utils + FAISS) ---\n",
        "!pip -q install -U \"transformers==4.44.2\" \"sentence-transformers==3.0.1\" \\\n",
        "                   \"bitsandbytes>=0.43.1,<0.47\" \"accelerate>=0.33.0\" \\\n",
        "                   faiss-cpu rank-bm25 arabic-reshaper python-bidi\n",
        "\n",
        "# --- APT (OCR fallback & PDF tools; optional but recommended) ---\n",
        "!apt -yq install ocrmypdf tesseract-ocr-fas poppler-utils >/dev/null\n",
        "\n",
        "# Sanity print\n",
        "import importlib.metadata as im, torch, sys\n",
        "def v(p):\n",
        "    try: return im.version(p)\n",
        "    except: return \"not-installed\"\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"transformers:\", v(\"transformers\"))\n",
        "print(\"sentence-transformers:\", v(\"sentence-transformers\"))\n",
        "print(\"faiss-cpu:\", v(\"faiss-cpu\"))\n",
        "print(\"bitsandbytes:\", v(\"bitsandbytes\"))\n",
        "print(\"accelerate:\", v(\"accelerate\"))\n",
        "print(\"arabic-reshaper:\", v(\"arabic-reshaper\"), \"| python-bidi:\", v(\"python-bidi\"))\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSNbSvA_pTC4",
        "outputId": "d926e251-6f9a-43c0-edbc-39c5d41d2244"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: apt-extracttemplates failed: No such file or directory\n",
            "E: Sub-process /usr/sbin/dpkg-preconfigure --apt || true received signal 2.\n",
            "E: Failure running script /usr/sbin/dpkg-preconfigure --apt || true\n",
            "torch: 2.8.0+cu126\n",
            "transformers: 4.44.2\n",
            "sentence-transformers: 3.0.1\n",
            "faiss-cpu: 1.12.0\n",
            "bitsandbytes: 0.46.1\n",
            "accelerate: 1.10.1\n",
            "arabic-reshaper: 3.0.0 | python-bidi: 0.6.6\n",
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os, json, re, shutil, subprocess, uuid\n",
        "import fitz  # PyMuPDF\n",
        "from tqdm import tqdm\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "\n",
        "# --- Path to your Drive folder (change if needed) ---\n",
        "FOLDER = \"/content/drive/MyDrive/biologybooks\"  # e.g. contains: 1.pdf, 2.pdf, 3.pdf\n",
        "OUT_DIR = Path(\"/content/rag_fa\")\n",
        "OCR_DIR = OUT_DIR / \"ocr_cache\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OCR_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def fa_normalize(s: str) -> str:\n",
        "    # Basic Persian normalization (no hazm needed)\n",
        "    s = s.replace(\"\\u064a\", \"ی\").replace(\"\\u0649\", \"ی\").replace(\"\\u06cc\", \"ی\")  # yeh\n",
        "    s = s.replace(\"\\u0643\", \"ک\").replace(\"\\u06a9\", \"ک\")  # keh\n",
        "    # remove diacritics\n",
        "    s = re.sub(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u06D6-\\u06ED]\", \"\", s)\n",
        "    # collapse spaces\n",
        "    s = re.sub(r\"[ \\t\\r\\f\\v]+\", \" \", s)\n",
        "    s = re.sub(r\"\\s*\\n\\s*\", \"\\n\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def fa_shape_bidi(s: str) -> str:\n",
        "    # Many extractors already return correct order; but if you see reversed text,\n",
        "    # enable shaping+bidi. We keep it on by default for consistency.\n",
        "    try:\n",
        "        reshaped = arabic_reshaper.reshape(s)\n",
        "        return get_display(reshaped)\n",
        "    except Exception:\n",
        "        return s\n",
        "\n",
        "def extract_with_pymupdf(pdf_path: Path) -> list:\n",
        "    \"\"\"Return list[str] per page (UTF-8).\"\"\"\n",
        "    pages = []\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for p in range(len(doc)):\n",
        "            text = doc[p].get_text(\"text\") or \"\"\n",
        "            text = fa_normalize(text)\n",
        "            text = fa_shape_bidi(text)\n",
        "            pages.append(text)\n",
        "    return pages\n",
        "\n",
        "def ocr_pdf(src: Path, dst: Path):\n",
        "    # Fast, language=fas; keep vector, deskew, clean\n",
        "    cmd = [\n",
        "        \"ocrmypdf\",\n",
        "        \"--language\", \"fas\",\n",
        "        \"--skip-text\",               # don't OCR pages that already have text\n",
        "        \"--rotate-pages\", \"--deskew\",\n",
        "        \"--optimize\", \"1\",\n",
        "        \"--output-type\", \"pdf\",\n",
        "        str(src), str(dst)\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "def maybe_ocr_then_extract(pdf_path: Path) -> list:\n",
        "    pages = extract_with_pymupdf(pdf_path)\n",
        "    total_chars = sum(len(p) for p in pages)\n",
        "    if total_chars >= 500:   # likely digitally searchable already\n",
        "        return pages\n",
        "\n",
        "    # OCR fallback (scanned PDF)\n",
        "    ocr_path = OCR_DIR / f\"{pdf_path.stem}.ocr.pdf\"\n",
        "    if not ocr_path.exists():\n",
        "        try:\n",
        "            ocr_pdf(pdf_path, ocr_path)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"⚠️ OCR failed for {pdf_path.name}: {e}. Returning raw extract.\")\n",
        "            return pages\n",
        "    return extract_with_pymupdf(ocr_path)\n",
        "\n",
        "def chunk_pages(pages: list, doc_name: str, max_chars=900, overlap=150):\n",
        "    \"\"\"Simple paragraph-based chunking with overlap.\"\"\"\n",
        "    chunks = []\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        # split by paragraph boundaries\n",
        "        parts = [p.strip() for p in re.split(r\"\\n{2,}\", page) if p.strip()]\n",
        "        buf, clen = [], 0\n",
        "        for par in parts:\n",
        "            if clen + len(par) + 1 <= max_chars:\n",
        "                buf.append(par); clen += len(par) + 1\n",
        "            else:\n",
        "                if buf:\n",
        "                    text = \"\\n\".join(buf).strip()\n",
        "                    if text:\n",
        "                        chunks.append({\"doc\": doc_name, \"page\": i, \"text\": text})\n",
        "                    # start new buffer with overlap from the end\n",
        "                    tail = text[-overlap:] if overlap and len(text) > overlap else \"\"\n",
        "                    buf = [tail, par] if tail else [par]\n",
        "                    clen = sum(len(s)+1 for s in buf)\n",
        "                else:\n",
        "                    # very long single paragraph\n",
        "                    for j in range(0, len(par), max_chars - overlap):\n",
        "                        piece = par[j:j + (max_chars - overlap)]\n",
        "                        if j > 0 and overlap:\n",
        "                            piece = (par[max(0, j-overlap):j] + piece)\n",
        "                        piece = piece.strip()\n",
        "                        if piece:\n",
        "                            chunks.append({\"doc\": doc_name, \"page\": i, \"text\": piece})\n",
        "                    buf, clen = [], 0\n",
        "        if buf:\n",
        "            text = \"\\n\".join(buf).strip()\n",
        "            if text:\n",
        "                chunks.append({\"doc\": doc_name, \"page\": i, \"text\": text})\n",
        "    return chunks\n",
        "\n",
        "# --- Run extraction over folder ---\n",
        "folder = Path(FOLDER)\n",
        "pdfs = sorted([p for p in folder.iterdir() if p.suffix.lower()==\".pdf\"])\n",
        "print(\"PDFs:\", [p.name for p in pdfs])\n",
        "\n",
        "all_chunks = []\n",
        "report = []\n",
        "for pdf in tqdm(pdfs, desc=\"Processing PDFs\"):\n",
        "    pages = maybe_ocr_then_extract(pdf)\n",
        "    chs = chunk_pages(pages, pdf.name, max_chars=900, overlap=140)\n",
        "    all_chunks.extend(chs)\n",
        "    report.append((pdf.name, sum(len(x) for x in pages), len(pages), len(chs)))\n",
        "\n",
        "with open(OUT_DIR/\"chunks.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for c in all_chunks:\n",
        "        f.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"Extract report:\", report)\n",
        "print(\"Total chunks:\", len(all_chunks))\n",
        "print(\"Saved:\", str(OUT_DIR/\"chunks.jsonl\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__rsGfLvpT74",
        "outputId": "cdadb021-a879-4bfe-f066-5c546f206f5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDFs: ['1.pdf', '2.pdf', '3.pdf']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs: 100%|██████████| 3/3 [00:05<00:00,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extract report: [('1.pdf', 196869, 120, 313), ('2.pdf', 230954, 168, 377), ('3.pdf', 228017, 136, 365)]\n",
            "Total chunks: 1055\n",
            "Saved: /content/rag_fa/chunks.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "import numpy as np\n",
        "import faiss\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from rank_bm25 import BM25Okapi\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# If you haven't already done login() in another cell:\n",
        "# from getpass import getpass\n",
        "# from huggingface_hub import login\n",
        "# login(getpass(\"HF token: \"))\n",
        "\n",
        "# --- Load chunks ---\n",
        "CHUNKS_PATH = \"/content/rag_fa/chunks.jsonl\"\n",
        "chunks = [json.loads(line) for line in open(CHUNKS_PATH, encoding=\"utf-8\")]\n",
        "texts = [c[\"text\"] for c in chunks]\n",
        "\n",
        "# --- BM25 (light lexical recall; optional but cheap) ---\n",
        "bm25 = BM25Okapi([t.split() for t in texts])\n",
        "\n",
        "# --- Embeddings: GTE multilingual (strong for Persian) ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "embedder = SentenceTransformer(\"Alibaba-NLP/gte-multilingual-base\", device=device, trust_remote_code=True)\n",
        "# direct sentence list; normalize for IP similarity\n",
        "emb = embedder.encode(texts, batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
        "emb = emb.astype(\"float32\")\n",
        "\n",
        "# --- FAISS index (inner product on normalized vectors == cosine) ---\n",
        "index = faiss.IndexFlatIP(emb.shape[1])\n",
        "index.add(emb)\n",
        "print(\"FAISS index size:\", index.ntotal)\n",
        "\n",
        "# --- Reranker (cross-encoder; multilingual, efficient) ---\n",
        "from sentence_transformers import CrossEncoder\n",
        "reranker = CrossEncoder(\"BAAI/bge-reranker-v2-m3\", device=device, trust_remote_code=True)\n",
        "\n",
        "# --- Qwen loader with safe fallbacks (4-bit -> 8-bit -> fp16 -> cpu) ---\n",
        "def load_qwen(prefer_7b=True):\n",
        "    primary = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "    secondary = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "    order = [primary, secondary] if prefer_7b else [secondary, primary]\n",
        "    has_gpu = torch.cuda.is_available()\n",
        "\n",
        "    # 4-bit\n",
        "    try:\n",
        "        import bitsandbytes as bnb  # noqa\n",
        "        if has_gpu:\n",
        "            qcfg = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "            )\n",
        "            for mid in order:\n",
        "                tok = AutoTokenizer.from_pretrained(mid, use_fast=True, trust_remote_code=True)\n",
        "                llm = AutoModelForCausalLM.from_pretrained(\n",
        "                    mid, device_map=\"auto\", quantization_config=qcfg,\n",
        "                    torch_dtype=torch.bfloat16, trust_remote_code=True\n",
        "                )\n",
        "                return tok, llm, mid, \"4bit\"\n",
        "    except Exception as e:\n",
        "        print(\"⚠️  4-bit skipped:\", e)\n",
        "\n",
        "    # 8-bit\n",
        "    try:\n",
        "        import bitsandbytes as bnb  # noqa\n",
        "        if has_gpu:\n",
        "            qcfg = BitsAndBytesConfig(load_in_8bit=True)\n",
        "            for mid in order:\n",
        "                tok = AutoTokenizer.from_pretrained(mid, use_fast=True, trust_remote_code=True)\n",
        "                llm = AutoModelForCausalLM.from_pretrained(\n",
        "                    mid, device_map=\"auto\", quantization_config=qcfg,\n",
        "                    torch_dtype=torch.float16, trust_remote_code=True\n",
        "                )\n",
        "                return tok, llm, mid, \"8bit\"\n",
        "    except Exception as e:\n",
        "        print(\"⚠️  8-bit skipped:\", e)\n",
        "\n",
        "    # fp16 (GPU, no quantization) — prefer 3B to avoid OOM\n",
        "    if has_gpu:\n",
        "        try:\n",
        "            mid = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "            tok = AutoTokenizer.from_pretrained(mid, use_fast=True, trust_remote_code=True)\n",
        "            llm = AutoModelForCausalLM.from_pretrained(\n",
        "                mid, device_map=\"auto\", torch_dtype=torch.float16,\n",
        "                low_cpu_mem_usage=True, trust_remote_code=True\n",
        "            )\n",
        "            return tok, llm, mid, \"fp16\"\n",
        "        except Exception as e:\n",
        "            print(\"⚠️  fp16 skipped:\", e)\n",
        "\n",
        "    # CPU fallback\n",
        "    mid = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "    tok = AutoTokenizer.from_pretrained(mid, use_fast=True, trust_remote_code=True)\n",
        "    llm = AutoModelForCausalLM.from_pretrained(\n",
        "        mid, device_map=\"cpu\", torch_dtype=torch.float32, trust_remote_code=True\n",
        "    )\n",
        "    return tok, llm, mid, \"cpu32\"\n",
        "\n",
        "tok, llm, LLM_ID, MODE = load_qwen(prefer_7b=True)\n",
        "print(f\"✅ LLM: {LLM_ID} | mode={MODE}\")\n",
        "\n",
        "# --- Retrieval (BM25 + FAISS hybrid) ---\n",
        "def retrieve(query: str, top_k_vec=30, top_k_bm25=10, fuse_k=30):\n",
        "    q_norm = query.strip()\n",
        "    # vector\n",
        "    qv = embedder.encode([q_norm], normalize_embeddings=True)\n",
        "    sims, idxs = index.search(qv.astype(\"float32\"), top_k_vec)\n",
        "    vec_hits = set(idxs[0].tolist())\n",
        "    # bm25\n",
        "    bm = bm25.get_top_n(q_norm.split(), list(range(len(texts))), n=top_k_bm25)\n",
        "    bm_hits = set(bm)\n",
        "    # union then cut\n",
        "    cand = list(vec_hits.union(bm_hits))\n",
        "    # rerank cross-encoder\n",
        "    pairs = [[q_norm, texts[i]] for i in cand]\n",
        "    scores = reranker.predict(pairs, batch_size=64, show_progress_bar=False)\n",
        "    order = np.argsort(-scores)[:fuse_k]\n",
        "    ranked = [(cand[i], float(scores[i])) for i in order]\n",
        "    return ranked\n",
        "\n",
        "# --- Answer generation (Persian) ---\n",
        "def generate_answer(question: str, k=6, max_new_tokens=384, temperature=0.2, top_p=0.9):\n",
        "    ranked = retrieve(question, fuse_k=max(k, 6))\n",
        "    ctx_items = []\n",
        "    for i, (idx, sc) in enumerate(ranked[:k], 1):\n",
        "        c = chunks[idx]\n",
        "        cite = f\"- {c['doc']} | صفحه {c['page']}\"\n",
        "        ctx_items.append(cite + \"\\n\" + c[\"text\"])\n",
        "\n",
        "    context = \"\\n\\n---\\n\\n\".join(ctx_items)\n",
        "    # ChatML via tokenizer (works with Qwen)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\":\n",
        "         \"شما یک کمک‌یار فارسی دقیق و بی‌طرف هستید. فقط بر اساس متن‌های «ارجاع‌شده» پاسخ دهید. \"\n",
        "         \"اگر مطمئن نبودید، صادقانه بگویید که در منابع موجود پاسخ را پیدا نکرده‌اید.\"},\n",
        "        {\"role\": \"user\", \"content\":\n",
        "         f\"پرسش:\\n{question}\\n\\n\"\n",
        "         f\"متن‌های مرتبط:\\n{context}\\n\\n\"\n",
        "         \"خروجی را به فارسی و با این ساختار بده:\\n\"\n",
        "         \"۱) خلاصه یک‌جمله‌ای\\n۲) تعریف علمی کوتاه (۲–۳ جمله)\\n۳) مراحل گام‌به‌گام (بولت)\\n۴) نکات کلیدی (بولت)\\n۵) ارجاعات (فقط نام فایل و شماره صفحه)\"},\n",
        "    ]\n",
        "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tok([prompt], return_tensors=\"pt\").to(llm.device)\n",
        "    with torch.no_grad():\n",
        "        out = llm.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=temperature > 0,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            repetition_penalty=1.05,\n",
        "            eos_token_id=tok.eos_token_id,\n",
        "        )\n",
        "    text = tok.decode(out[0], skip_special_tokens=True)\n",
        "    # keep only the assistant part (after last user)\n",
        "    return text.split(messages[-1][\"content\"])[-1].strip(), [chunks[i][\"page\"] for i,_ in ranked[:k]]\n",
        "\n",
        "# --- Example usage ---\n",
        "q = \"هدف میتوز چیست و نتیجهٔ نهایی آن از نظر تعداد و شباهت یاخته‌ها چگونه است؟\"\n",
        "answer, pages = generate_answer(q, k=6, max_new_tokens=320)\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657,
          "referenced_widgets": [
            "6d28c902d9304cf0888ee048acc724f1",
            "1bb3cc89418149429af251b1f691d3eb",
            "d2d87237f8634f6c90dfd02f366498f1",
            "4ccd18d1f82342948269f1cff23a981a",
            "5630c5be62e94d628d1e2de11dc2bc92",
            "b1f36fdde10944019901b7d09475ab33",
            "74437b83a435436cbf6e17234d078b6c",
            "357d447c5e834c68a57255aeac247dab",
            "009d70d256724cd0ab16ace4377445eb",
            "ad0363dbcb89488a813171a13c960402",
            "8ae08697e84f4edbb07055604c5b8ce9",
            "4a5f2525b6f248e5a16a3209a3211d72",
            "d119891a6cb6422c9aefc97ec12f11e6",
            "cb45eac55de9425bb0252c9147823eaa",
            "1d0a477c5e984bd3ab23a248d8b7fc8f",
            "4f1a3b38953344e1ac71d039a487362a",
            "5f09d495d86d4414991d9df8e92745f0",
            "e9b8cf559a2d4fd883247523a6e263a8",
            "1e5dad7af216462b9bc2aab90a6d71e5",
            "0c40eb4c18d14b85983ce736c9b4acd8",
            "8e6b3b529cd8466abba451c1c5ffa464",
            "0c77bb37a58041219435cba14d27bc35"
          ]
        },
        "id": "rbu7fg6cpZOM",
        "outputId": "0a585b4d-08f2-41fb-b8e5-b300fe456310"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d28c902d9304cf0888ee048acc724f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index size: 1055\n",
            "⚠️  4-bit skipped: There was a specific connection error when trying to load Qwen/Qwen2.5-7B-Instruct:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/model.safetensors (Request ID: Root=1-68f35ded-35831dd666bbd1c55619a2d8;66f4103e-e212-4b4d-ab0d-7dfc230f699f)\n",
            "\n",
            "Invalid credentials in Authorization header\n",
            "⚠️  8-bit skipped: There was a specific connection error when trying to load Qwen/Qwen2.5-7B-Instruct:\n",
            "401 Client Error: Unauthorized for url: https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/resolve/main/model.safetensors (Request ID: Root=1-68f35dee-103331171e3c9e3b2da26b36;937260a4-edf8-4bc5-b9dd-3259822987ab)\n",
            "\n",
            "Invalid credentials in Authorization header\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a5f2525b6f248e5a16a3209a3211d72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LLM: Qwen/Qwen2.5-3B-Instruct | mode=fp16\n",
            "assistant\n",
            "۱) خلاصه یک‌جمله‌ای:\n",
            "هدف میتوز گسترش یک یاخته به یک یکسان است و نتیجه آن تولید یک یاخته‌ی جدید با شباهت بالایی به یاخته‌های قبلی است.\n",
            "\n",
            "۲) تعریف علمی کوتاه:\n",
            "هدف میتوز گسترش یک یاخته به یک یکسان است و نتیجه آن تولید یک یاخته‌ی جدید با شباهت بالایی به یاخته‌های قبلی است. این مراحل شامل چندین مرحله‌ی مختلف مانند گسترش یک یاخته به دو یاخته، سازگاری یاخته‌ها و تولید یاخته‌ی جدید است.\n",
            "\n",
            "۳) مراحل گام‌به‌گام:\n",
            "مرحله اول: گسترش یک یاخته به دو یاخته (پروکاریوت‌ها و اکسون‌ها).\n",
            "مرحله دوم: سازگاری یاخته‌ها (پروکاریوت‌ها و اینترون‌ها).\n",
            "مرحله سوم: ت\n"
          ]
        }
      ]
    }
  ]
}